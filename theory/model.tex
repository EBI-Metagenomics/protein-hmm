\section{Model}

\begin{definition}\label{def:mp}
  A Markov process is a stochastic process $Q_1, \dots$ for which
  \begin{equation*}
    p(Q_t=q_t \gv Q_1=q_1, Q_2=q_2, \dots, Q_{t-1}=q_{t-1}) = p(Q_t=q_t \gv Q_{t-1}=q_{t-1}).
  \end{equation*}
  The possible values of $Q_t$ form a finite set $\set{Q}$ called the state space.
\end{definition}

\begin{definition}\label{def:hmm}
  Let $\set{A}$ be a non-empty finite set of symbols. Let $Q_1, Q_2, \dots$ be a Markov process and
  let $S_1, S_2, \dots$ be a stochastic process for which
  \begin{equation*}
    p(S_t\in\set{A} \gv Q_1=q_1, Q_2=q_2, \dots, Q_t=q_t) = p(S_t\in\set{A} \gv Q_t=q_t).
  \end{equation*}
  The pair $(Q_t, S_t)$ is a hidden Markov model (HMM) with alphabet $\set{A}$.
\end{definition}

Let $\arr{z}=z_1z_2 \dots z_L$ be a sequence emitted by an HMM.\@
The marginal likelihood of $\arr{z}$ is defined by
\begin{equation}\label{eq:hml}
  \mathrm{ML}(\arr{z}) \eqdef p(S_1=z_1, S_2=z_2, \dots, S_L=z_L).
\end{equation}

The standard HMM definition is often extended to include states that do not emit symbols. Those
states are referred to as silent states and are useful to describe a missing alignment position, for
example. This section goes a step further by defining a more general hidden Markov model that
accounts for states that instead emit sequence of symbols of variable length, including zero-length
sequences.

\begin{definition}
  Let $\set{A}$ be a non-empty finite set of symbols, $k\in\field{N}_0$, and define
  $\set{B}=\bigcup_{i=0}^k\set{A}^i$.
  Let $Q_1, Q_2, \dots$ be a Markov process and let $S_1, S_2, \dots$ be a stochastic process for
  which
  \begin{equation*}
    p(S_t\in\set{B} \gv Q_1=q_1, Q_2=q_2, \dots, Q_t=q_t)
    = p(S_t\in\set{B} \gv Q_t=q_t).
  \end{equation*}
  The pair $(Q_t, S_t)$ is an invisible Markov model (IMM) with alphabet $\set{A}$ and
  limit $k$.
\end{definition}

Let $\arr{z}=z_1 .. z_L$ be a sequence emitted by an IMM.\@
The marginal likelihood of $\arr{s}$ cannot be written as in Eq.~\eqref{eq:hml} since
we've lost the the order association between symbols and states.
Instead, the marginal likelihood is given by
\begin{equation}\label{eq:ml}
  \mathrm{ML}(\arr{z}) \eqdef \sum_{t=1}^{\infty} p(S_{1..t}=\arr{z}, S_{t+1}\neq \emptyset),
\end{equation}
where $S_{1..t}$ denotes the concatenation of the random variables $S_1$, $S_2$,
$\dots$, and $S_t$.

\begin{remark}
  The notation $p(S_{1..t}=\arr{z})$ is equal to the summation of the probabilities of every valid
  association between the random variables $S_1, S_2, \dots, S_t$ and the subsequences of $\arr{z}$,
  including the possibility of a random variable emitting an empty sequence. For example, let $a$ be
  sequence composed of a single symbol $a$. We have $p(S_{1..2}=a) = p(S_1=a, S_2=\emptyset) +
  p(S_1=\emptyset, S_2=a)$.
\end{remark}

\subsection{Viterbi}

Let us consider first the Viterbi method applied to HMMs for a given sequence $\arr{z}$ of length
$L$.
Let
\begin{equation*}
  \viterbi(q_t) \eqdef
  \begin{dcases*}
    \umax{q_{1..t-1}} \{ p(S_{1..t}=z_{1..t}, Q_{1..t}=q_{1..t}) \} & if $t>1$ \\
    p(S_1=z_1 \gv Q_1=q_1) p(Q_1=q_t)                               & if $t=1$
  \end{dcases*}
\end{equation*}
be the so-called Viterbi score. It is the maximum probability among all state paths that ends in
$q_t$ and generates the prefix $z_{1..t}$ from sequence $\arr{z}$.
The function domain of $\viterbi(q_t)$ is such that $t \in \{1, 2, \dots, L\}$.

Viterbi score can also be defined in a recursive fashion as follows:
\begin{equation*}
\begin{split}
  \viterbi(q_t)
  &= p(S_t=z_t \gv Q_t=q_t) \umax{q_{1..t-1}}
    \{ p(Q_t=q_t \gv Q_{t-1}=q_{t-1}) p(S_{1..t-1}=z_{1..t-1}, Q_{1..t-1}=q_{1..t-1}) \} \\
  &= p(S_t=z_t \gv Q_t=q_t) \umax{q_{t-1}}
    \{ p(Q_t=q_t \gv Q_{t-1}=q_{t-1})
    \umax{q_{1..t-2}} \{ p(S_{1..t}=z_{1..t-1}, Q_{1..t}=q_{1..t-1}) \} \} \\
  &= p(S_t=z_t \gv Q_t=q_t) \umax{q_{t-1}} \{ p(Q_t=q_t \gv Q_{t-1}=q_{t-1})
    \viterbi(q_{t-1}) \},
\end{split}
\end{equation*}
for $t>1$.

The notation $\viterbi(q_t)$ under the HMM context conveys three crucial information: (i) we are at
step $t$ of the HMM process; (ii) we are querying something about some state $q_t \in \set{Q}$
regarding (iii) the prefix $z_{1..t}$. The same notation under the IMM context loses the information
(iii): the index $t$ no longer unambigously defines a prefix. We will instead use
$\viterbi_{q_t,f_t}(i)$ to define the Viterbi score, for which $i$ defines the prefix $z_{1..i}$. We
also make use of index $f_t$, which determines the sequence length that state $q_t \in \set{Q}$ is
being queried about.
In summary, the notation $\viterbi_{q_t,f_t}(i)$ under the IMM context will convey four crucial
information:
\begin{itemize}
  \item We are at step $t$ of the IMM process;
  \item We query something about some state $q_t \in \set{Q}$;
  \item The query regards the prefix $z_{1..i}$;
  \item And we conjecture that the last $f_t$ symbols of $z_{1..i}$ have been emitted at step $t$ by
    state $q_t$.
\end{itemize}
For the sake of notation clarity, let us denote $z_{i(f_t)..i} \eqdef z_{i-f_t+1..i}$ as the
$f_t$-length tail of a sequence $z_{1..i}$.

The Viterbi score of an IMM regarding a sequence $\arr{z}$ of length $L$ is defined by
\begin{equation*}
  \viterbi_{i}(q_t,f_t) \eqdef
  \begin{dcases*}
    \umax{\substack{q_{1..t-1}\\f_{1..t-1}}}
    \{
      p(S_{1..t}=z_{1..i}, Q_{1..t}=q_{1..t} ~;~ F_{1..t}=f_{1..t})
    \}                                                                  & if $t>1$\\
    p(S_1=z_{1..f_1} \gv Q_1=q_t) p(Q_1=q_1)                            & if $t=1$
  \end{dcases*}
\end{equation*}
It is the maximum probability among all state paths that ends in
$q_t$ emitting $z_{i(f_t)..i}$ and generates the prefix $z_{1..i}$ from sequence $\arr{z}$.
The function domain of $\viterbi_{i}(q_t,f_t)$ is such that $t \in \{1, 2, \dots\}$, $i \in \{0, 1,
\dots, L\}$, $f_t \in \{0, 1, \dots, i\}$, and $q_t \in \set{Q}$.

Viterbi score for IMM can also be defined in a recursive way as follows:
\begin{equation*}
  \begin{split}
    \viterbi_{i}(q_t,f_t)
    &= p(S_t=z_{i(f_t)..i} \gv q_t)
      \uumax{q_{t-1}}{f_{t-1}}
      \{
        p(q_t \gv q_{t-1})
        \uumax{q_{1..t-2}}{f_{1..t-2}}
        \{
          p(S_{1..t-1}=z_{1..i-f_t}, q_{1..t-1} ~;~ f_{1..t-1})
        \}
      \}\\
    &= p(S_t=z_{i(f_t)..i} \gv q_t)
      \uumax{q_{t-1}}{f_{t-1}}
      \{
        p(q_t \gv q_{t-1}) \viterbi_{i-f_t}(q_{t-1},f_{t-1})
      \},
  \end{split}
\end{equation*}
for $t>1$.

\subsection{Not sure}

Let $q_{1..t}$ be a sequence of states (also known as state path).
The likelihood of sequence $\arr{z}$ for state path $q_{1..t}$ is given by
\begin{align*}
  \mathrm{L}(\arr{z}, q_{1..t}) = p(V_{1..t}=\arr{z}, Q_{1..t}=q_{1..t}).
\end{align*}
Note that
\begin{align*}
  \mathrm{L}(\arr{z}, q_{1..t}) &= \sum_{l_t=0}^L p(V_{1..t}=\arr{z}, L_t=l_t,
  Q_{1..t}=q_{1..t})\\
  &= \sum_{l_t=0}^L p(V_{1..t-1}=z_{1..l_t}, V_t=z_{l_t+1..L}, Q_{1..t-1}=q_{1..t-1}, Q_t=q_t)\\
  &= \sum_{l_t=0}^L p(V_t=z_{l_t+1..L} \gv Q_t=q_t) p(Q_t=q_t \gv Q_{t-1}=q_{t-1})
  \mathrm{L}(z_{1..l_t}, q_{1..t-1})
\end{align*}

% Let
% \begin{align*}
%   \mathrm{L}(z_{1..l_t}, z_{l_t+1..l_t+f_t}, q_{1..t})
%   &= p(V_t=z_{l_t+1..l_t+f_t} \gv Q_t=q_t) p(Q_t=q_t \gv Q_{t-1}=q_{t-1})\\
%   &p(V_{1..t-1} = z_{1..l_t}, Q_{1..t-1}=q_{1..t-1}).
% \end{align*}
% Let
% \begin{align*}
%   g_t(z_{1..l_t}, z_{l_t+1..l_t+f_t}, q_t)
%   &= \max_{q_{t-1}, f_{t-1}}
%   \Big\{
%     p(V_t=z_{l_t+1..l_t+f_t} \gv Q_t=q_t) p(Q_t=q_t \gv Q_{t-1}=q_{t-1}) \\
%     &g_{t-1}(z_{1..l_{t-1}}, z_{l_{t-1}+1..l_{t-1}+f_{t-1}}, q_{t-1})
%   \Big\}.\\
%   g_1(\emptyset, z_{1..f_1}, q_1)
%   &= p(V_1=z_{1..f_1} \gv Q_1=q_1) p(Q_1=q_1)
% \end{align*}

\subsection{Discussion}

For computational reasons, it would be useful to have an upper bound on the summation of the
marginal likelihood.
We will define a type of IMM that has such a feature.

\begin{definition}
  A cycle is any probable sequence of states that starts and ends with the same state.
\end{definition}

\begin{definition}
  A quiet state is a state that has a non-zero probability of emitting an empty sequence.
\end{definition}

\begin{definition}
  A quiet cycle is any cycle having only quiet states.
\end{definition}

\begin{corollary}
  Let $M$ be the number of states of the IMM.\@ If it has no quiet cycles, any sequence of $M$ states
  will have emitted at least one symbol.
\end{corollary}

If IMM has no quiet cycles, there is always a $N \leq L\cdot M$ such that
\begin{equation*}
  \mathrm{ML}(\arr{z}) = \sum_{t=1}^{L\cdot M} p(V_{1..t}=\arr{z}, L_t<L).
\end{equation*}
